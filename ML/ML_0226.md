# 온도에 따른 Ozone량 예측

##  Tensorflow 구현

> ```python
> import numpy as np
> import pandas as pd
> import matplotlib.pyplot as plt
> from scipy import stats     # 이상치 처리를 위해서 필요
> import tensorflow as tf     # tensorflow 구현
> from sklearn import linear_model  # sklearn으로 simple linear regression 구현
> from sklearn.preprocessing import MinMaxScaler # normalization 전처리
> 
> 
> # Raw Data Loading
> df = pd.read_csv('C:/Users/USER/Desktop/multicampus/ozone/ozone.csv')
> training_data = df[['Temp','Ozone']]   # 153 rows × 2 columns
> 
> # 결측치부터 처리!
> # 결측치를 찾아서 제거!
> training_data = training_data.dropna(how='any')
> # display(training_data)    # 116 rows × 2 columns
> 
> # 이상치 처리(outlier)
> # z-score를 이용해서 outlier를 처리
> zscore_threshold = 1.8
> 
> # Temp에 대한 outlier(지대점)
> tmp = ~(np.abs(stats.zscore(training_data['Temp'])) > zscore_threshold)
> training_data = training_data.loc[tmp]
> # display(training_data)   # 110 rows × 2 columns
> 
> # Ozone에 대한 outlier
> tmp = ~(np.abs(stats.zscore(training_data['Ozone'])) > zscore_threshold)
> training_data = training_data.loc[tmp]
> # display(training_data)   # 103 rows × 2 columns
> 
> ###########################
> # 정규화 처리를 진행(Min-Max Scaler)
> # 직접구현해도 되지만 sklearn을 이용해서 처리!
> 
> # Min-Max Scaler라고 불리는 객체를 생성
> # 독립변수와 종속변수에 대해서 각각 만듬!
> scaler_x = MinMaxScaler()  # 객체 생성
> scaler_t = MinMaxScaler()  # 객체 생성
> scaler_x.fit(training_data['Temp'].values.reshape(-1,1))
> scaler_t.fit(training_data['Ozone'].values.reshape(-1,1))
> # print(scaler_x.n_samples_seen_, scaler_x.data_max_, 
> #       scaler_x.data_min_, scaler_x.feature_range)
> training_data['Temp'] = scaler_x.transform(training_data['Temp'].values.reshape(-1,1))
> training_data['Ozone'] = scaler_t.transform(training_data['Ozone'].values.reshape(-1,1))
> 
> display(training_data)
> 
> 
> # Training Data Set
> x_data = training_data['Temp'].values.reshape(-1,1)
> t_data = training_data['Ozone'].values.reshape(-1,1)
> 
> # placeholder
> X = tf.placeholder(shape=[None,1], dtype=tf.float32)
> T = tf.placeholder(shape=[None,1], dtype=tf.float32)
> 
> # Weight & bias
> W = tf.Variable(tf.random.normal([1,1]), name='weight')
> b = tf.Variable(tf.random.normal([1]), name='bias')
> 
> # Hypothesis
> H = tf.matmul(X,W) + b
> 
> # loss function
> loss = tf.reduce_mean(tf.square(H-T))
> 
> # train
> train = tf.train.GradientDescentOptimizer(learning_rate=1e-4).minimize(loss)
> 
> # session, 초기화
> sess = tf.Session()
> sess.run(tf.global_variables_initializer())
> 
> for step in range(300000):
>     _, W_val, b_val, loss_val = sess.run([train, W, b, loss], 
>                                          feed_dict={X: x_data, T: t_data})
>     
>     if step % 30000 == 0:
>         print('W : {}, b : {}, loss : {}'.format(W_val,b_val,loss_val))
> 
> ################출력##################
> 
> W : [[0.39896443]], b : [1.0173838], loss : 0.7891387343406677
> W : [[0.24676716]], b : [0.24518694], loss : 0.05058763176202774
> W : [[0.39457205]], b : [0.16574354], loss : 0.04112405702471733
> W : [[0.50260407]], b : [0.10798614], loss : 0.036080677062273026
> W : [[0.5814576]], b : [0.06582753], loss : 0.03339332342147827
> W : [[0.6390068]], b : [0.03505438], loss : 0.03196141496300697
> W : [[0.68099576]], b : [0.01259447], loss : 0.031198522076010704
> W : [[0.71168125]], b : [-0.00379668], loss : 0.030791541561484337
> W : [[0.73404306]], b : [-0.01575487], loss : 0.030574878677725792
> W : [[0.750333]], b : [-0.02447379], loss : 0.03045949898660183
> ```



## Python 구현

> ```python
> import numpy as np
> import pandas as pd
> import matplotlib.pyplot as plt
> from scipy import stats     # 이상치 처리를 위해서 필요
> import tensorflow as tf     # tensorflow 구현
> from sklearn import linear_model  # sklearn으로 simple linear regression 구현
> from sklearn.preprocessing import MinMaxScaler # normalization 전처리
> 
> df = pd.read_csv('C:/Users/USER/Desktop/multicampus/ozone/ozone.csv')
> training_data = df[['Temp','Ozone']]   # 153 rows × 2 columns
> 
> # 결측치부터 처리
> training_data = training_data.dropna(how='any')
> 
> zscore_threshold = 1.8
> 
> tmp = ~(np.abs(stats.zscore(training_data['Temp'])) > zscore_threshold)
> training_data = training_data[tmp]
> 
> tmp = ~(np.abs(stats.zscore(training_data['Ozone'])) > zscore_threshold)
> training_data = training_data[tmp]
> 
> scaler_x = MinMaxScaler()
> scaler_t = MinMaxScaler()
> 
> scaler_x.fit(training_data['Temp'].values.reshape(-1,1))
> scaler_t.fit(training_data['Ozone'].values.reshape(-1,1))
> 
> training_data['Temp'] = scaler_x.transform(training_data['Temp'].values.reshape(-1,1))
> training_data['Ozone'] = scaler_t.transform(training_data['Ozone'].values.reshape(-1,1))
> 
> x_data = training_data['Temp'].values.reshape(-1,1)
> t_data = training_data['Ozone'].values.reshape(-1,1)
> 
> W = np.random.rand(1,1)
> b = np.random.rand(1)
> 
> def pred(x):
>     
>     return np.dot(x,W)+b
> 
> def loss(input_obj):
>     input_W = input_obj[0]
>     input_b = input_obj[1]
>     
>     y = np.dot(x_data,input_W) +input_b
>     return np.mean(np.power((t_data-y),2))
> 
> def numerical_derivative(f,x):
>     
>     delta_x = 1e-4
>     derivate = np.zeros_like(x)
>     it = np.nditer(x, flags = ['multi_index'])
>     
>     while not it.finished:
>         idx = it.multi_index
>         tmp = x[idx]
>         
>         x[idx] = tmp + delta_x
>         fx_plus = f(x)
>         
>         x[idx] = tmp - delta_x
>         fx_minus = f(x)
>         
>         derivate[idx] = (fx_plus - fx_minus) /( 2* delta_x)
>         x[idx] = tmp
>         
>         it.iternext()
> 
>     return derivate
> 
> learning_rate = 1e-4
> 
> for step in range(300000):
>     input_param = np.concatenate((W.ravel(),b.ravel()),axis = 0)
>     result = learning_rate * numerical_derivative(loss,input_param)
>     
>     W = W - result[:1].reshape(1,1)
>     b = b - result[1:]
>     if step % 30000 == 0:
>         print('W : {}, b : {}'.format(W,b))
> ```

## Scikit-learn 구현

> ```python
> # Training Data Set
> x_data = training_data['Temp'].values.reshape(-1,1)
> t_data = training_data['Ozone'].values.reshape(-1,1)
> 
> model = linear_model.LinearRegression()
> model.fit(x_data,t_data)
> 
> print('W : {}, b : {}'.format(model.coef_, model.intercept_))
> 
> ################출력##################
> 
> W : [[0.79468511]], b : [-0.04818192]
> ```



## Graph로 비교

> ```python
> fig = plt.figure()
> fig_tensorflow = fig.add_subplot(1,2,1)
> fig_sklearn = fig.add_subplot(1,2,2)
> 
> fig_tensorflow.set_title('Tensorflow Graph')
> fig_sklearn.set_title('sklearn Graph')
> 
> fig_tensorflow.scatter(x_data,t_data)
> fig_tensorflow.plot(x_data,x_data*W_val.ravel() + b_val, color='r')
> 
> fig_sklearn.scatter(x_data,t_data)
> fig_sklearn.plot(x_data,x_data*model.coef_.ravel() + model.intercept_, color='b')
> 
> fig.tight_layout()
> plt.show()
> 
> ```
>
> - 출력
>
>   ![image-20210303151643260](C:%5CUsers%5CUSER%5CDesktop%5CTIL%5CML%5Cmd-images%5Cimage-20210303151643260.png)



## prediction

> ```python
> 
> # tensorflow를 이용
> tensorflow_result = sess.run(H, feed_dict={X:[[62]]})
> print(tensorflow_result)
> 
> # python 이용
> print(pred([[62]]))
> 
> # sklearn을 이용
> sklearn_result = model.predict([[62]])
> print(sklearn_result)    # [[49.22229492]]
> ######################출력#########################
> 
> [[48.692375]]
> [[47.39180043]]
> [[49.22229492]]
> ```
>
> 

# 독립변수가 여러개인 Multiple Linear Regression

> ![image-20210303160703535](C:%5CUsers%5CUSER%5CDesktop%5CTIL%5CML%5Cmd-images%5Cimage-20210303160703535.png)
>
> 
>
> 



# 온도, 태양광세기, 바람세기를 이용하여 Ozone량을 예측

## Tensorflow 구현

>  ```python
> %reset
> import numpy as np
> import pandas as pd
> from scipy import stats     # 이상치 처리를 위해서 필요
> import tensorflow as tf     # tensorflow 구현
> from sklearn import linear_model  # sklearn으로 simple linear regression 구현
> from sklearn.preprocessing import MinMaxScaler # normalization 전처리 (minmax는 이상치에 취약)
> 
> # Raw Data Loading
> df = pd.read_csv('C:/Users/USER/Desktop/multicampus/ozone/ozone.csv')
> training_data = df[['Temp','Wind','Solar.R','Ozone']]   # 153 r
> 
> # 결측치를 찾아서 제거
> training_data = training_data.dropna(how='any')
> 
> # 이상치 처리(outlier)
> # z-score를 이용해서 outlier를 처리
> zscore_threshold = 1.8
> 
> for col in training_data.columns:
>     tmp = ~(np.abs(stats.zscore(training_data[col])) > zscore_threshold)
>     training_data = training_data.loc[tmp]
> 
> # 정규화 처리를 진행(Min-Max Scaler)
> # 직접구현해도 되지만 sklearn을 이용해서 처리해 보아요!
> 
> # Min-Max Scaler라고 불리는 객체를 생성
> # 이 객체를 두개 만들꺼예요! 독립변수와 종속변수에 대해서 각각 만들어줘요!
> scaler_x = MinMaxScaler()  # 객체 생성
> scaler_t = MinMaxScaler()  # 객체 생성
> scaler_x.fit(training_data[['Temp','Wind','Solar.R']].values)
> scaler_t.fit(training_data['Ozone'].values.reshape(-1,1))
> 
> training_data_x = scaler_x.transform(training_data[['Temp','Wind','Solar.R']].values)
> training_data_t = scaler_t.transform(training_data['Ozone'].values.reshape(-1,1))
> 
> # Training Data Set
> x_data = training_data_x
> t_data = training_data_t
> 
> # placeholder
> X = tf.placeholder(shape=[None,3], dtype=tf.float32)
> T = tf.placeholder(shape=[None,1], dtype=tf.float32)
> 
> # Weight & bias
> W = tf.Variable(tf.random.normal([3,1]), name='weight')
> b = tf.Variable(tf.random.normal([1]), name='bias')
> 
> # Hypothesis
> H = tf.matmul(X,W) + b
> 
> # loss function
> loss = tf.reduce_mean(tf.square(H-T))
> 
> # train
> train = tf.train.GradientDescentOptimizer(learning_rate=1e-4).minimize(loss)
> 
> # session, 초기화
> sess = tf.Session()
> sess.run(tf.global_variables_initializer())
> 
> for step in range(300000):
>     _, W_val, b_val, loss_val = sess.run([train, W, b, loss], 
>                                          feed_dict={X: x_data, T: t_data})
>     
>     if step % 30000 == 0:
>         print('W : {}, b : {}, loss : {}'.format(W_val,b_val,loss_val))
>         
> ############################출력#################################
> 
> W : [[0.02387494]
>  [0.8465957 ]
>  [0.46784005]], b : [-0.41763538], loss : 0.1994745284318924
> W : [[0.39010474]
>  [0.4380988 ]
>  [0.41901138]], b : [-0.3029706], loss : 0.08606309443712234
> W : [[0.5830832 ]
>  [0.17643695]
>  [0.3631895 ]], b : [-0.24607752], loss : 0.04788923263549805
> W : [[0.68894327]
>  [0.01504768]
>  [0.32138172]], b : [-0.19962563], loss : 0.03388187289237976
> W : [[ 0.7442844 ]
>  [-0.08644703]
>  [ 0.2900932 ]], b : [-0.16147204], loss : 0.028513407334685326
> W : [[ 0.77066624]
>  [-0.15188381]
>  [ 0.26662824]], b : [-0.12996109], loss : 0.026302576065063477
> W : [[ 0.7807321 ]
>  [-0.19537523]
>  [ 0.24898487]], b : [-0.10378645], loss : 0.02529250830411911
> W : [[ 0.7818073 ]
>  [-0.22529425]
>  [ 0.23563905]], b : [-0.08195473], loss : 0.02477019652724266
> W : [[ 0.77826285]
>  [-0.2466557 ]
>  [ 0.22548242]], b : [-0.06367421], loss : 0.024466121569275856
> W : [[ 0.77280205]
>  [-0.26248664]
>  [ 0.21768455]], b : [-0.04838363], loss : 0.024273093789815903
>  ```



## Python 구현

> ```python
> %reset
> import numpy as np
> import pandas as pd
> import matplotlib.pyplot as plt
> from scipy import stats     # 이상치 처리를 위해서 필요
> import tensorflow as tf     # tensorflow 구현
> from sklearn import linear_model  # sklearn으로 simple linear regression 구현
> from sklearn.preprocessing import MinMaxScaler # normalization 전처리
> 
> df = pd.read_csv('C:/Users/USER/Desktop/multicampus/ozone/ozone.csv')
> training_data = df[['Temp','Wind','Solar.R','Ozone']]   # 153 rows × 2 columns
> 
> training_data = training_data.dropna(how = 'any')
> 
> zscore_threshold =1.8
> for i in training_data.columns:
>     tmp = ~(np.abs(stats.zscore(training_data[i])) > zscore_threshold)
>     training_data = training_data.loc[tmp]
> 
> scaler_x = MinMaxScaler()
> scaler_t = MinMaxScaler()
> 
> scaler_x.fit(training_data[['Temp','Wind','Solar.R']].values)
> scaler_t.fit(training_data['Ozone'].values.reshape(-1,1))
> 
> training_data_x = scaler_x.transform(training_data[['Temp','Wind','Solar.R']].values)
> training_data_t = scaler_t.transform(training_data[['Ozone']].values.reshape(-1,1))
> 
> x_data = training_data_x
> t_data = training_data_t
> 
> W = np.random.rand(3,1)
> b = np.random.rand(1)
> 
> def pred(x):
>     return np.dot(x,W)+b
> 
> def loss(input_obj):
>     input_W = input_obj[:-1].reshape(-1,1)
>     input_b = input_obj[-1:]
>     
>     y = np.dot(x_data,input_W)+input_b
>     return np.mean(np.power((t_data-y),2))
> def numerical_derivative(f,x):
>     
>     delta_x = 1e-4
>     derivate = np.zeros_like(x)
>     it = np.nditer(x, flags = ['multi_index'])
>     
>     while not it.finished:
>         idx = it.multi_index
>         tmp = x[idx]
>         
>         x[idx] = tmp + delta_x
>         fx_plus = f(x)
>         
>         x[idx] = tmp - delta_x
>         fx_minus = f(x)
>         
>         derivate[idx] = (fx_plus - fx_minus) /( 2* delta_x)
>         x[idx] = tmp
>         
>         it.iternext()
> 
>     return derivate
> 
> learning_rate = 1e-4
> 
> for step in range(300000):
>     input_param = np.concatenate((W.ravel(),b.ravel()),axis = 0)
>     result = learning_rate * numerical_derivative(loss,input_param)
>     
>     W = W - result[:-1].reshape(-1,1)
>     b = b - result[-1:]
>     if step % 30000 == 0:
>         input_param = np.concatenate((W.ravel(),b.ravel()),axis = 0)
>         print('W : {}, b : {}, loss : {}'.format(W,b,loss(input_param)))
>         
> ############################출력#################################        
> 
> W : [[0.8227357 ]
>  [0.10753093]
>  [0.28318037]], b : [0.15212691], loss : 0.22897331643519564
> W : [[ 0.73638214]
>  [-0.11169423]
>  [ 0.16419253]], b : [-0.07242626], loss : 0.02694385024625803
> W : [[ 0.75631011]
>  [-0.17593688]
>  [ 0.17621187]], b : [-0.05839323], loss : 0.02529090445654245
> W : [[ 0.76334947]
>  [-0.21787033]
>  [ 0.18373338]], b : [-0.0458154], loss : 0.024605535591227305
> W : [[ 0.76356697]
>  [-0.24599966]
>  [ 0.18829371]], b : [-0.03466372], loss : 0.02428930617311604
> W : [[ 0.76039963]
>  [-0.26545057]
>  [ 0.19091861]], b : [-0.02485504], loss : 0.02412392728295413
> W : [[ 0.7557618 ]
>  [-0.27933618]
>  [ 0.19229199]], b : [-0.01628025], loss : 0.024026714686845772
> W : [[ 0.75069224]
>  [-0.28956614]
>  [ 0.19286917]], b : [-0.00881966], loss : 0.02396431326633672
> W : [[ 0.74573063]
>  [-0.29732725]
>  [ 0.1929523 ]], b : [-0.00235266], loss : 0.023921940857161945
> W : [[ 0.74113583]
>  [-0.30336941]
>  [ 0.19274074]], b : [0.00323655], loss : 0.023892223161214834 
> ```
>
> 

## Scikit-learn 구현

> ```python
> # sklearn을 이용해서 구현해 보아요!
> # Training Data Set
> x_data = training_data[['Temp','Wind','Solar.R']].values
> t_data = training_data['Ozone'].values.reshape(-1,1)
> 
> model = linear_model.LinearRegression()
> model.fit(x_data,t_data)
> 
> print('W : {}, b : {}'.format(model.coef_, model.intercept_))
> 
> ############################출력#################################
> 
> W : [[ 1.9400749  -2.7453281   0.05651878]], b : [-97.42698439]
> ```



## prediction

> ```python
> # tensorflow를 이용 예측
> predict_data = np.array([[80,10,150]])
> scaled_predict_data = scaler_x.transform(predict_data)
> 
> tensorflow_result = sess.run(H, feed_dict={X:scaled_predict_data})
> 
> tensorflow_result=scaler_t.inverse_transform(tensorflow_result)
> print(tensorflow_result)
> 
> # python를 이용 예측
> predict_data = np.array([[80,10,150]])
> scaled_predict_data = scaler_x.transform(predict_data)
> python_result=pred(scaled_predict_data)
> python_result=scaler_t.inverse_transform(python_result)
> print(python_result)
> 
> # sklearn을 이용 예측
> sklearn_result = model.predict([[80,10,150]])
> print(sklearn_result)    # [[49.22229492]]
> 
> ############################출력#################################
> 
> [[38.55627]]
> [[38.79794881]]
> [[38.8035437]]
> ```

